{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing only passed attempts until the very end where the average is shown.\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Iteration 185, Passed! Reward -175.0\n",
      "Iteration 228, Passed! Reward -168.0\n",
      "Iteration 241, Passed! Reward -167.0\n",
      "Iteration 297, Passed! Reward -171.0\n",
      "Iteration 350, Passed! Reward -174.0\n",
      "Iteration 355, Passed! Reward -173.0\n",
      "Iteration 360, Passed! Reward -197.0\n",
      "Iteration 361, Passed! Reward -175.0\n",
      "Iteration 392, Passed! Reward -190.0\n",
      "Iteration 429, Passed! Reward -195.0\n",
      "Iteration 436, Passed! Reward -180.0\n",
      "Iteration 439, Passed! Reward -178.0\n",
      "Iteration 441, Passed! Reward -176.0\n",
      "Iteration 443, Passed! Reward -177.0\n",
      "Iteration 452, Passed! Reward -180.0\n",
      "Iteration 460, Passed! Reward -183.0\n",
      "Iteration 470, Passed! Reward -186.0\n",
      "Iteration 480, Passed! Reward -174.0\n",
      "Iteration 491, Passed! Reward -177.0\n",
      "Iteration 496, Passed! Reward -174.0\n",
      "Iteration 503, Passed! Reward -182.0\n",
      "Iteration 512, Passed! Reward -160.0\n",
      "Iteration 516, Passed! Reward -176.0\n",
      "Iteration 521, Passed! Reward -163.0\n",
      "Iteration 526, Passed! Reward -155.0\n",
      "Iteration 552, Passed! Reward -189.0\n",
      "Iteration 554, Passed! Reward -184.0\n",
      "Iteration 576, Passed! Reward -168.0\n",
      "Iteration 577, Passed! Reward -177.0\n",
      "Iteration 580, Passed! Reward -176.0\n",
      "Iteration 582, Passed! Reward -182.0\n",
      "Iteration 586, Passed! Reward -185.0\n",
      "Iteration 607, Passed! Reward -183.0\n",
      "Iteration 617, Passed! Reward -184.0\n",
      "Iteration 646, Passed! Reward -191.0\n",
      "Iteration 654, Passed! Reward -173.0\n",
      "Iteration 662, Passed! Reward -185.0\n",
      "Iteration 669, Passed! Reward -172.0\n",
      "Iteration 672, Passed! Reward -180.0\n",
      "Iteration 676, Passed! Reward -184.0\n",
      "Iteration 679, Passed! Reward -193.0\n",
      "Iteration 684, Passed! Reward -172.0\n",
      "Iteration 691, Passed! Reward -185.0\n",
      "Iteration 722, Passed! Reward -173.0\n",
      "Iteration 731, Passed! Reward -169.0\n",
      "Iteration 739, Passed! Reward -187.0\n",
      "Iteration 742, Passed! Reward -190.0\n",
      "Iteration 745, Passed! Reward -165.0\n",
      "Iteration 747, Passed! Reward -160.0\n",
      "Iteration 754, Passed! Reward -179.0\n",
      "Iteration 755, Passed! Reward -172.0\n",
      "Iteration 762, Passed! Reward -172.0\n",
      "Iteration 763, Passed! Reward -181.0\n",
      "Iteration 764, Passed! Reward -180.0\n",
      "Iteration 767, Passed! Reward -159.0\n",
      "Iteration 769, Passed! Reward -174.0\n",
      "Iteration 773, Passed! Reward -172.0\n",
      "Iteration 777, Passed! Reward -170.0\n",
      "Iteration 779, Passed! Reward -173.0\n",
      "Iteration 792, Passed! Reward -176.0\n",
      "Iteration 794, Passed! Reward -169.0\n",
      "Iteration 831, Passed! Reward -192.0\n",
      "Iteration 832, Passed! Reward -170.0\n",
      "Iteration 858, Passed! Reward -172.0\n",
      "Iteration 859, Passed! Reward -185.0\n",
      "Iteration 865, Passed! Reward -184.0\n",
      "Iteration 867, Passed! Reward -187.0\n",
      "Iteration 905, Passed! Reward -174.0\n",
      "Iteration 913, Passed! Reward -169.0\n",
      "Iteration 944, Passed! Reward -192.0\n",
      "Iteration 955, Passed! Reward -189.0\n",
      "Iteration 956, Passed! Reward -192.0\n",
      "Final correct average: -177.72222222222223\n"
     ]
    }
   ],
   "source": [
    "import gym; import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    def getAction():\n",
    "        if not state in policy: policy[state] = actions[np.random.randint(0,number_actions)]\n",
    "        return policy[state]\n",
    "    def update():\n",
    "        def getReward(Q,state,action):\n",
    "          if not (state,action) in Q: Q[state,action] = 0\n",
    "          return Q[state,action]\n",
    "        Q[(state,action)] = getReward(Q,state,action) + learning_rate * (reward + gamma * max([getReward(Q, future_state, future_action) for future_action in actions]) if done == False else 0 - getReward(Q, state, action))\n",
    "        future_rewards = [getReward(Q, state, future_action) for future_action in actions]\n",
    "        policy[state] = actions[future_rewards.index(max(future_rewards))]\n",
    "    def getState(obs): return tuple([int(np.digitize(obs[i], [np.linspace(env.observation_space.low[i], env.observation_space.high[i], 10) for i in range(2)][i])) for i in range(2)])\n",
    "    print('Showing only passed attempts until the very end where the average is shown.')\n",
    "    env = gym.make('MountainCar-v0')\n",
    "    number_actions = env.action_space.n\n",
    "    Q, policy, actions, gamma, learning_rate = {}, {}, [i for i in range(number_actions)], 0.99, 0.5\n",
    "    ra = []\n",
    "    for i in range(1000):\n",
    "        state, total_reward = getState(env.reset()), 0\n",
    "        for j in range(200):\n",
    "            x = np.random.random()\n",
    "            action = np.random.randint(0, number_actions) if x < learning_rate else getAction()\n",
    "            learning_rate *= gamma if x < learning_rate else 1\n",
    "            state2, reward, done, _ = env.step(action)\n",
    "            future_state = getState(state2)\n",
    "            total_reward += reward\n",
    "            # env.render()\n",
    "            if done:\n",
    "                if total_reward < -199: reward = -50; update();\n",
    "                elif total_reward > -199: ra.append(total_reward); print(\"Iteration {}, Passed! Reward {}\".format(i, total_reward))\n",
    "                break\n",
    "            update()\n",
    "            state = future_state\n",
    "    print(\"Final correct average: {}\".format(float(sum(ra))/float(len(ra))))\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
